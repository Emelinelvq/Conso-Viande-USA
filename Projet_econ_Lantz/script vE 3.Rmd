---
title: "Projet_économétrie_Lantz"
author: "Thomas, Emeline, Benoît et Lucie"
date: "2026-01-12"
output: html_document
editor_options: 
  chunk_output_type: console
---
# Introduction 
La consommation de viande aux États-Unis occupe une place centrale dans les dynamiques agroalimentaires mondiales, tant par son niveau élevé que par son influence sur les marchés internationaux. 
Depuis l’après-guerre, les États-Unis figurent parmi les premiers producteurs et consommateurs mondiaux de viande bovine, porcine et avicole, avec des niveaux de consommation par habitant supérieurs à la moyenne des pays de l’OCDE. 
Selon les rapports de la FAO (2025), la transition alimentaire observée au XXe siècle s’est traduite par une augmentation soutenue de la demande en protéines animales, portée par la croissance des revenus, l’urbanisation et les gains de productivité agricole.

D’un point de vue économique, la demande de viande est étroitement liée au revenu disponible, aux prix relatifs et aux préférences des consommateurs (Hestermann, 2020). 
Les travaux empiriques fondés sur des systèmes de demande montrent que les élasticités-revenu et prix diffèrent selon les types de viande, la volaille apparaissant généralement plus élastique que le bœuf (Luke, 2025). 
Les analyses publiées par l’OCDE dans les Perspectives agricoles soulignent que la substitution entre viandes rouges et blanches s’est accentuée depuis les années 1980, sous l’effet combiné des prix relatifs, des préoccupations sanitaires et des innovations technologiques dans la filière avicole.

Par ailleurs, les perturbations récentes des chaînes d’approvisionnement durant la pandémie de COVID-19 ont généré des hausses de prix et une volatilité accrue, confirmant les résultats de la Banque mondiale sur la transmission des chocs mondiaux aux marchés alimentaires domestiques (Erol, 2022).

La dynamique des prix constitue un déterminant essentiel des fluctuations de consommation. 
Les chocs pétroliers des années 1970 ont entraîné une hausse des coûts de production (alimentation animale, transport), répercutée partiellement sur les prix à la consommation. 
Plus récemment, la crise financière de 2008 a affecté le pouvoir d’achat des ménages, conduisant à une réallocation vers des sources de protéines moins coûteuses (Glynn T, 2022).

À moyen et long terme, les perspectives de consommation dépendent également des tendances démographiques, des politiques publiques et des préoccupations environnementales. 
Les scénarios prospectifs de la FAO et de l’OCDE (2020) anticipent un ralentissement de la croissance de la consommation de viande rouge dans les pays développés, tandis que la volaille continuerait de progresser en raison de son coût relatif et de son empreinte carbone plus faible. 
Les analyses statistiques appliquées aux séries temporelles américaines montrent ainsi des ruptures structurelles associées aux chocs économiques et réglementaires, justifiant l’utilisation de modèles économétriques pour prévoir la consommation future (Zheng, 2008).

Dans ce contexte, la construction d’un modèle de prédiction de la consommation de viande aux États-Unis s’inscrit dans une double perspective : comprendre les déterminants économiques et structurels de la demande, et anticiper les évolutions futures dans un environnement marqué par l’incertitude des prix, les transitions nutritionnelles et les contraintes environnementales. 
Une approche économétrique rigoureuse, fondée sur les données historiques, constitue ainsi un outil pertinent d’aide à la décision pour les acteurs publics et privés du secteur agroalimentaire.

## Préparation de la session R 
```{r, include=FALSE}
# Ouverture des librairies 
# Spécificité du package readxl
#remove.packages("readxl")
#install.packages("readxl", type = "source")

# Installation des librairies
#install.packages("lmtest")
#install.packages("tseries")
#install.packages("glmnet")

library(readxl)
library(lmtest)
library(tseries)
library(glmnet)
library(strucchange)
library(sandwich)
library(car)
library(tseries)
library(tidyverse)
```

## Importer et préparer les données
Les données utilisées sont annuelles et couvrent la période 2004–2024. La consommation de viande est issue de l’USDA Economic Research Service (ERS), qui fournit des statistiques détaillées sur les produits animaux aux États-Unis.  
Les données de PIB et de population proviennent de la Banque mondiale (World Bank).  
L’indice des prix à la consommation ainsi que le prix moyen du bœuf sont extraits de la base FRED de la Federal Reserve Bank of St. Louis.
L’utilisation de sources institutionnelles garantit la fiabilité et la cohérence des séries statistiques employées dans l’analyse économétrique. 
La consommation de viande est mesurée en milliards de livres (retail equivalent of disappearance). Les variables explicatives incluent le PIB, la population, l’indice des prix à la consommation et le prix moyen du bœuf.

```{r, include=FALSE}
# Données chargées manuellement
data <- read_excel("CV_USA.xlsx")
head(data)

# Convertir Year en variable numérique
data$Year <- as.numeric(data$Year)
```

## Transformation logarithmique et en réel 
Nous avons décidé de passer en log-log afin de capturer les élasticités-revenu et prix. Par ailleurs, nous avons transformé les prix nominaux en prix réels (déflaté par l'indice des prix) afin de neutraliser l'impact de l'inflation, ce qui nous semble indispensable dans le cadre d'une analyse de long-terme. Afin de lisser l'effet démographique, le PIB a été divisé par la population pour obtenir un PIB par habitant.

```{r, include=FALSE}
# Transformation logarithmique (pour obtenir des élasticités + hypothèse de normalité + hypothèse de variance constante)
data_log <- data
data_log$CV <- log(data$CV/data$Population)
data_log$PIB <- log(data$PIB)
data_log$Population <- log(data$Population)
data_log$CPI <- log(data$CPI)
data_log$Beef_price <- log(data$Beef_price)
```


Voici un graphique de la consommation de viande en logaritme sur le période de 2004 à 2024 : 

```{r, include = FALSE}
#plot(data_log$Year, data_log$CV, type="l", main="Log consommation de viande") # grosse chute de la consommation de viande en 2015. Pourquoi ? Comment est-ce qu'on l'explique ?
```

```{r, echo = FALSE}
# Passage en prix réels
data_reel <- data
data_reel$CV <- log(data$CV/data$Population)
data_reel$PIB <- log(data$PIB/(data$Population*(data$CPI/100)))
data_reel$Beef_price <- log(data$Beef_price/(data$CPI/100))
```

```{r, include = FALSE}

ggplot(data_reel, aes(x = Year, y = CV)) +
  # Ligne principale
  geom_line(color = "#2c3e50", linewidth = 1) +
  # Points pour marquer chaque année
  geom_point(color = "#34495e", size = 2, alpha = 0.7) +
  # Titres et labels
  labs(
    title = "Consommation réelle de viande de bœuf",
    subtitle = "Série temporelle 2004-2024 (Logarithmes)",
    x = "Années",
    y = "log(Consommation réelle)",
    caption = "Note : Les données sont exprimées en logarithmes de valeurs réelles."
  ) +
  # Thème professionnel
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold", color = "#1a252f"),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(), # On épure l'axe X pour plus de clarté
    axis.title = element_text(face = "italic"),
    axis.line = element_line(color = "#bdc3c7")
  )
```
On observe une baisse de la consommation de viande entre 2008 et 2015, cette baisse s'explique très probablement par la récession qui a touché les USA en 2008. A partir de 2015, on observe une augmentation assez régulière de la consommation de boeuf, et ce jusqu'en 2024. 

```{r, include=FALSE}
#mettons tout ce joli monde dans une matrice
X_reel <- model.matrix(CV ~ PIB +  Beef_price, data = data_reel)[, -1]
CV_reel <- data_reel$CV
```


## Création du modèle de régression 
Nous allons maintenant essayer d'expliquer cette rupture de 2015 avec un modèle de régression log-log. 

```{r}
# Modèle de régression log-log avec prix réels

modele_reel <- lm(CV ~ PIB + Beef_price, data = data_reel) 

summary(modele_reel)

```
On obtient ici un R2 assez faible, nous allons donc essayer d'ajuster le modèle, notamment via l'ajout de variables


## Ajout données prix soja et poulet
Nous avons décidé de rajouter comme variable le prix du soja (global price of soybean) et du poulet (prix moyen global ou américain pour le poulet?) car nos résultats précédents ne nous satisfaisaient pas. Les données proviennent de la Federal Reserve Bank of St. Louis. De même, on convertit les prix en termes réels.
```{r, include=FALSE}
# Importation 
moyenne_prix_soja <- read_excel("moyenne prix soja.xlsx")
chicken_data <- read_excel("chicken data.xlsx")

soja <- moyenne_prix_soja %>%
  rename(prix_soja = `global price of soybeans`)

poulet <- chicken_data %>%
  mutate(Year = année) %>%
  select(-année) %>%
  rename(prix_poulet = `chicken avg price`)

soja$Year   <- as.numeric(soja$Year)
soja$prix_soja   <- as.numeric(soja$prix_soja)
poulet$Year <- as.numeric(poulet$Year)
data$Year   <- as.numeric(data$Year)

# Passage des variables soja et poulet en variables réelles 
data_log_sojchick <- soja %>%
  inner_join(poulet, by = "Year") %>%
  inner_join(data, by = "Year")

data_log_sojchick$CV <- log(data$CV/data$Population)
data_log_sojchick$PIB <- log(data$PIB)
data_log_sojchick$Population <- log(data$Population)
data_log_sojchick$CPI <- log(data$CPI)
data_log_sojchick$Beef_price <- log(data$Beef_price)
data_log_sojchick$prix_soja <- log(soja$prix_soja)
data_log_sojchick$prix_poulet <- log(poulet$prix_poulet)
```



```{r, include=FALSE}
# Variable réel plutôt que nominal
data_reel_sojchick <- data_log_sojchick
data_reel_sojchick$CV <- log(data$CV/data$Population) #attention à ne pas déflater
data_reel_sojchick$PIB <- log(data$PIB/(data$Population*(data$CPI/100)))
data_reel_sojchick$Beef_price <- log(data$Beef_price/(data$CPI/100))
data_reel_sojchick$prix_soja <- log(soja$prix_soja/(data$CPI/100))
data_reel_sojchick$prix_poulet <- log(poulet$prix_poulet/(data$CPI/100))

#mettons tout ce joli monde dans une matrice
X_reel_sojchick <- model.matrix(CV ~ PIB +  Beef_price + prix_soja + prix_poulet, data = data_reel_sojchick)[, -1]
CV_reel_sojchick <- data_reel_sojchick$CV
```

On crée un nouveau modèle log-log avec ces variables
```{r}

# Modèle avec prix réels
modele_reel_sojchick <- lm(CV ~ PIB + Beef_price + prix_soja + prix_poulet, data = data_reel_sojchick) # modèle régression linéaire avec les données en réel

summary(modele_reel_sojchick)

```


```{r, include=FALSE}
#PK CALCULER LE R2 ? est ce que c'est juste pour vérification ? pcq on l'a dans le summary autrement 
CV_pred_reel_sojchick <- predict(modele_reel_sojchick, newx = X_reel_sojchick)
r2 <- 1 - sum((CV_reel_sojchick - CV_pred_reel_sojchick)^2) / sum((CV_reel_sojchick - mean(CV_reel_sojchick))^2)


```

# Différents tests et ajustement du modèle 
On teste dans un premier temps la stabilité temporelle. L'idée est de déterminer si des chocs exogènes ou des changements structurels de consommation sont survenus et auraient alors modifié les comportements des consommateurs et les relations économiques. 
Au vu du changement de tendance qui apparait en 2015, il se pourrait qu'il y ait un véritable changement structurel dans le comportement des consommateurs autour de l'année 2015.  

On commence par un test de Cusum square afin de déterminer s'il y a une rupture et la date de cette rupture le cas échéant. 

```{r}
## Problèmes et tests
#1 Stabilité temporelle

# Cusum square

y <- as.matrix(data_reel_sojchick$CV) # variable expliquée 
X <- cbind(
  1,                       # constante
  data_reel_sojchick$PIB,            # on ajoute les variables explicatives 
  data_reel_sojchick$Beef_price,
  data_reel_sojchick$prix_poulet,
  data_reel_sojchick$prix_soja
)
w <- recresid(y, X)       # résidus récursifs
CUSUMSQ <- cumsum(w^2) / sum(w^2) # construction du cusumsq
nrow(X) == length(y) # check de sécurité --> TRUE donc c'est bon pas de problème de longueur ou de NA 
X <- as.matrix(X)
y <- as.matrix(y)

# Visualisation graphique 
plot(CUSUMSQ,
     type = "l",
     lwd = 2,
     ylab = "CUSUM of Squares",
     xlab = "Temps",
     main = "Test CUSUMSQ – Stabilité du modèle")
abline(h = c(0.05, 0.95), lty = 2, col = "red")


# Test adaptaion code cours 
n <- nrow(X)  # nombre d'observations
k <- ncol(X)-1
# Résidus récursifs
rr <- recresid(y, X)

# Carrés
rr2 <- rr^2

# Somme des carrés totale (pour normaliser)
scr <- sum(rr2)

# Statistique cumulé (r_s)
cumrr <- cumsum(rr2)/scr

# Indices
nk1 <- n - k - 1
kp2 <- k + 2
t1 <- 1:nk1
t2 <- (kp2):n

# Valeur critique c0 (exemple pour alpha=0.05)
c0 <- 0.18915  # à adapter si n ou k change

# Limites inférieure et supérieure
smin <- ((t2 - k) / (n - k)) - c0
smax <- ((t2 - k) / (n - k)) + c0

# On aligne les longueurs
cumrr_trunc <- cumrr[kp2:n]  # pour que cumrr, smin et smax aient même longueur

cusum2 <- cbind(smin, cumrr_trunc, smax)

# Graphique final
matplot(t2, cusum2, type = "l", lty = 1, col = c("red", "black", "red"),
        xlab = "Observations", ylab = "CUSUMSQ",
        main = "Test CUSUM of Squares")
legend("topleft", legend=c("smin","cumrr","smax"),
       col=c("red","black","red"), lty=1)

```

La courbe ne reste en pas entre les bornes, elle sort en 2011. Cela veut dire qu'il y a une instabilité temporelle liée à une rupture structurelle donc au moins un coefficient change dans le temps. Une rupture temporelle aurait eu lieu en 2011


```{r, include = FALSE}

#jsp quoi faire de ce test
cusum <- efp(CV ~ PIB + Beef_price + prix_soja + prix_poulet, data = data_reel_sojchick, type = "Rec-CUSUM")
#plot(cusum) 

```

On fait ensuite un test de Chow pour vérifier la date de rupture.

```{r}

# Test de chow
sctest(CV_reel_sojchick ~ X_reel_sojchick, type="Chow", point = 7) 

```

La p-value est inférieure à 0,05, on observe donc bien une rupture temporelle en 2011

On ajoute donc une dummy pour corriger l'instabilité temporelle.

```{r}

# On corrige encore avec la dummy pour 2011

# Création d’une variable dummy : 0 avant 2011, 1 à partir de 2011
data_reel_sojchick$post2011 <- ifelse(data_reel_sojchick$Year >= 2011, 1, 0)
modele_reel_sojchick_dummy <- lm(CV ~ PIB + Beef_price + post2011 + prix_soja + prix_poulet, 
                      data = data_reel_sojchick)
summary(modele_reel_sojchick_dummy) 

# r2
summary(modele_reel_sojchick_dummy)$r.squared       # R² classique

summary(modele_reel_sojchick_dummy)$adj.r.squared   # R² ajusté (corrige le nombre de variables)


```

L'ajout de Dummy permet d'augmenter la significativité du modèle, notamment avec un R² augmenté. On remarque également que la dummy est très significative. Nous avons donc décidé de continuer avec ce modèle.


```{r}

#2 - Test d'autocorrélation d'ordre 1 (Durbin-Watson)
dwtest(modele_reel_sojchick_dummy) 

```

On obtient une valeur de DW inférieure à 2 et une p-value inférieure à 0.05, il y a donc une autocorrélation positive. 


```{r}

#3 - Test hétéroscédasticité (Breusch-Pagan)
bptest(modele_reel_sojchick_dummy)
```

On obtient une p-value inférieure à 0,05 donc nous sommes toujours en présence d'hétéroscédasticité.  

Les tests de diagnostic révélant à la fois une autocorrélation des résidus et une hétéroscédasticité, les erreurs standards sont corrigées selon la méthode de Newey-West afin d’obtenir des estimations robustes.

```{r}

# Correction 
coeftest(modele_reel_sojchick_dummy, vcov = NeweyWest(modele_reel_sojchick_dummy, lag = 1)) # corrige les erreurs-types pour autocorrélation d’ordre 1 et hétéroscédasticité

```

Après correction des erreurs standards selon la méthode de Newey-West, le PIB, la variable dummy post-2011 et le prix du poulet demeurent significatifs, confirmant la robustesse de ces effets. En revanche, les prix du bœuf et du soja ne présentent pas d’effet statistiquement significatif.

```{r, include=FALSE}

# Visualisation - jsp ce que c'est ça ?
plot(modele_reel_sojchick, wich = 1) # On observe la tendance à la courbure des résidus ce qui n'est pas optimal
```

```{r}
#4 - Test de la multicollinéarité (VIF (Variance Inflation Factor)) 
vif(modele_reel_sojchick_dummy)


```

L'analyse de la colinéarité via les tests VIF montre des scores inférieurs à 10 pour l'ensemble des variables. Nous en concluons que le modèle ne souffre pas de multicolinéarité excessive, ce qui garantit la stabilité des coefficients estimés.

```{r}

#5 - Vérification de la normalité des résidus (Jarque-Bera)
jarque.bera.test(residuals(modele_reel_sojchick_dummy)) # Les résidus sont normaux 

# Visualisation graphique 
qqnorm(residuals(modele_reel_sojchick_dummy))
qqline(residuals(modele_reel_sojchick_dummy)) 

```
La p-value est très élevée (bien au-dessus de 0,05), donc on ne rejette pas l’hypothèse nulle.
Autrement dit, les résidus du modèle sont compatibles avec une distribution normale.


## 
D'après ce modèle, décrire les résultats ce qui est significatif ce qui ne l'est pas et un peu de littérature pour valider ça 

## Bootstrap 
```{r}
library(ggplot2)
library(dplyr)

# 1. On récupère la toute dernière observation réelle (2024)
last_obs <- CV_USA %>% 
  filter(Year == 2024) %>% 
  select(Year, CV)

# 2. On prépare les données de prédiction (2025-2030)
# (Ici je reprends tes calculs précédents de future_data)
forecast_data <- future_data %>% 
  select(Year, CV = CV_real_fit, lwr, upr)

# 3. On crée un dataframe spécifique pour la ligne de prévision 
# en ajoutant 2024 au début des prévisions
prediction_line <- data.frame(
  Year = c(last_obs$Year, forecast_data$Year),
  CV   = c(last_obs$CV,   forecast_data$CV),
  lwr  = c(last_obs$CV,   forecast_data$lwr), # On part de la valeur exacte
  upr  = c(last_obs$CV,   forecast_data$upr)
)

# 4. Le Graphique corrigé
ggplot() +
  # Ligne Historique (arrête en 2024)
  geom_line(data = history_plot, aes(x = Year, y = CV), color = "black", size = 1) +
  geom_point(data = history_plot, aes(x = Year, y = CV), color = "black", size = 1.5) +
  
  # Ligne de Prédiction (commence en 2024, donc pas de trou)
  geom_line(data = prediction_line, aes(x = Year, y = CV), color = "#2ecc71", size = 1, linetype = "dashed") +
  
  # Ruban d'incertitude (commence aussi en 2024)
  geom_ribbon(data = prediction_line, aes(x = Year, ymin = lwr, ymax = upr), fill = "#2ecc71", alpha = 0.2) +
  
  # Ligne verticale de démarcation
  geom_vline(xintercept = 2024, linetype = "dotted", color = "red", size = 0.8) +
  
  scale_x_continuous(breaks = seq(min(history_plot$Year), 2030, 2)) +
  labs(title = "Consommation de Viande : Historique et Projection 2030",
       subtitle = "La prévision est raccordée à la dernière valeur réelle (2024)",
       x = "Année", y = "Consommation (Valeur Réelle)") +
  theme_minimal()
```

## Bootstrap - modèle dynamique 
```{r}
library(dplyr)
library(tidyr)

# Création du décalage (lag) dans les données d'entraînement
data_dynamique <- data_reel_sojchick %>%
  mutate(CV_lag = lag(CV)) %>%
  drop_na() # On enlève la première ligne qui n'a pas de passé

# Estimation du nouveau modèle dynamique
modele_dyn <- lm(CV ~ CV_lag + PIB + Beef_price + prix_soja + prix_poulet, 
                 data = data_dynamique)

# On vérifie si Newey-West est toujours nécessaire (souvent le lag réduit l'autocorrélation)
# coeftest(modele_dyn, vcov = NeweyWest(modele_dyn))

# Initialisation
forecast_years <- 2025:2030
n_years <- length(forecast_years)
last_log_cv <- tail(data_dynamique$CV, 1) # La valeur de 2024

# On prépare les prédicteurs futurs (comme avant)
future_preds <- data.frame(Year = forecast_years) %>%
  mutate(
    PIB = predict(lm(PIB ~ Year, data = data_dynamique), newdata = .),
    Beef_price = predict(lm(Beef_price ~ Year, data = data_dynamique), newdata = .),
    prix_soja = predict(lm(prix_soja ~ Year, data = data_dynamique), newdata = .),
    prix_poulet = predict(lm(prix_poulet ~ Year, data = data_dynamique), newdata = .)
  )

# Simulation Bootstrap récursive
n_boot <- 1000
resid_dyn <- residuals(modele_dyn)
boot_results <- matrix(NA, nrow = n_boot, ncol = n_years)

set.seed(123)
for(b in 1:n_boot) {
  current_lag <- last_log_cv
  for(t in 1:n_years) {
    # On construit la ligne de données pour l'année t
    new_data <- data.frame(
      CV_lag = current_lag,
      PIB = future_preds$PIB[t],
      Beef_price = future_preds$Beef_price[t],
      prix_soja = future_preds$prix_soja[t],
      prix_poulet = future_preds$prix_poulet[t]
    )
    # Prédiction + un résidu aléatoire
    pred_t <- predict(modele_dyn, newdata = new_data) + sample(resid_dyn, 1)
    boot_results[b, t] <- pred_t
    current_lag <- pred_t # Le résultat devient le lag pour t+1
  }
}

# Conversion en réel avec le CPI (comme précédemment)
mod_cpi <- lm(CPI ~ Year, data = CV_USA)
future_cpi <- predict(mod_cpi, newdata = data.frame(Year = forecast_years))

boot_real <- t(exp(t(boot_results)) * (future_cpi / 100))

# Synthèse des résultats
forecast_final <- data.frame(
  Year = forecast_years,
  CV = apply(boot_real, 2, median),
  lwr = apply(boot_real, 2, quantile, 0.025),
  upr = apply(boot_real, 2, quantile, 0.975)
)

# Ajout du point de raccord 2024
raccord <- CV_USA %>% filter(Year == 2024) %>% select(Year, CV) %>% 
  mutate(lwr = CV, upr = CV)
plot_data_dyn <- bind_rows(raccord, forecast_final)

# Graphique
ggplot() +
  geom_line(data = CV_USA, aes(x = Year, y = CV), color = "black", size = 1) +
  geom_line(data = plot_data_dyn, aes(x = Year, y = CV), color = "#3498db", linetype = "dashed", size = 1) +
  geom_ribbon(data = plot_data_dyn, aes(x = Year, ymin = lwr, ymax = upr), fill = "#3498db", alpha = 0.2) +
  geom_vline(xintercept = 2024, linetype = "dotted") +
  theme_minimal() +
  labs(title = "Prévision Dynamique de la Consommation",
       subtitle = "Modèle avec variable retardée (Inertie de consommation)",
       y = "Consommation Réelle", x = "Année")
```

## Rajout variable maïs
```{r}
# 1. Ajoute les données à ton dataframe (exemple rapide)
data_reel_sojchick$prix_mais_nominal <- c(2.06, 2.00, 3.04, 4.20, 4.06, 3.55, 5.18, 
                                          6.22, 6.89, 4.46, 3.70, 3.61, 3.36, 3.36, 
                                          3.61, 3.56, 4.53, 6.00, 6.60, 4.80, 4.24)

# 2. Transformation en log-réel
data_reel_sojchick$prix_mais <- log(data_reel_sojchick$prix_mais_nominal / (data$CPI / 100))

# 3. Nouveau modèle avec Maïs
modele_mais <- lm(CV ~ CV + PIB + Beef_price + prix_soja + prix_poulet + prix_mais, 
                  data = data_reel_sojchick)
summary(modele_mais)
```


## Prédictions avec scénario 
```{r}
future <- data.frame(Year=2025:2030)

last <- tail(data_reel_sojchick, 1)

lastPIB <- last$PIB
lastBeef <- last$Beef_price
lastSoja <- last$prix_soja
lastPoulet <- last$prix_poulet

future$PIB[1] <- lastPIB
future$Beef_price[1] <- lastBeef
future$prix_soja[1] <- lastSoja
future$prix_poulet[1] <- lastPoulet

for(i in 2:nrow(future)){
  future$PIB[i] <- future$PIB[i-1]*1.02
  future$Beef_price[i] <- future$Beef_price[i-1]*1.01
  future$prix_soja[i] <- future$prix_soja[i-1]*1.005
  future$prix_poulet[i] <- future$prix_poulet[i-1]*0.993
}

future$CV_pred <- predict(modele, newdata=future)
future


```


```{r}
#test
last <- tail(data, 1)
last_soja <- tail(soja,1)
last_poulet <- tail(poulet,1)

future_lvl <- data.frame(Year=2025:2030)

future_lvl$PIB[1] <- last$PIB
future_lvl$Population[1] <- last$Population
future_lvl$CPI[1] <- last$CPI
future_lvl$Beef_price[1] <- last$Beef_price
future_lvl$prix_soja[1] <- last_soja$prix_soja
future_lvl$prix_poulet[1] <- last_poulet$prix_poulet

for(i in 2:nrow(future_lvl)){
  future_lvl$PIB[i] <- future_lvl$PIB[i-1]*1.02        # +2%
  future_lvl$Population[i] <- future_lvl$Population[i-1]*1.02  # +2%
  future_lvl$CPI[i] <- future_lvl$CPI[i-1]*1.03       # +3%
  
  future_lvl$Beef_price[i] <- future_lvl$Beef_price[i-1]*0.99    # -1% par an
  future_lvl$prix_soja[i] <- future_lvl$prix_soja[i-1]*0.998      # légèrement diminuer
  future_lvl$prix_poulet[i] <- future_lvl$prix_poulet[i-1]*0.993  # -0,7% par an, ok si tu veux diminuer
}


future <- data.frame(
PIB = log(future_lvl$PIB/(future_lvl$Population*(future_lvl$CPI/100))),
Beef_price = log(future_lvl$Beef_price/(future_lvl$CPI/100)),
prix_soja = log(future_lvl$prix_soja/(future_lvl$CPI/100)),
prix_poulet = log(future_lvl$prix_poulet/(future_lvl$CPI/100))
)

modele_predict_sdummy <- lm(
  CV ~ PIB + Beef_price + prix_soja + prix_poulet,
  data = data_reel_sojchick
)

pred_log <- predict(modele_predict_sdummy, newdata=future)

CV_pred <- exp(pred_log) * (future_lvl$CPI/100)

pred <- predict(modele_predict_sdummy, newdata = future, interval = "prediction")
# fit  -> valeur centrale
# lwr  -> borne basse
# upr  -> borne haute

CV_fit <- exp(pred[, "fit"]) * (future_lvl$CPI/100)
CV_lwr <- exp(pred[, "lwr"]) * (future_lvl$CPI/100)
CV_upr <- exp(pred[, "upr"]) * (future_lvl$CPI/100)

plot_data <- data.frame(
  Year = future_lvl$Year,
  fit = CV_fit,
  lwr = CV_lwr,
  upr = CV_upr
)

library(ggplot2)

ggplot(plot_data, aes(x = Year, y = fit)) +
  geom_line(size = 1.2) +
  geom_ribbon(aes(ymin=lwr, ymax=upr), alpha = 0.2) +
  labs(
    title = "Prévision de la consommation de viande",
    y = "Consommation (niveau)",
    x = "Année"
  ) +
  theme_minimal()

hist <- data.frame(
  Year = data$Year,
  CV = data$CV
)

ggplot() +
  geom_line(data=hist, aes(Year, CV)) +
  geom_line(data=plot_data, aes(Year, fit)) +
  geom_ribbon(data=plot_data, aes(Year, ymin=lwr, ymax=upr), alpha=0.2) +
  theme_minimal()

```

```{r}
library(dplyr)

# -----------------------------
# 1️⃣ Création du dataframe futur
# -----------------------------
years <- 2023:2030  # horizon 2030
n_years <- length(years)

# Valeurs de départ à partir de la dernière année réelle
last_row <- tail(data_reel_sojchick, 1)

future_lvl <- data.frame(
  year = years,
  PIB = NA,
  Population = NA,
  CPI = NA,
  Beef_price = NA,
  prix_soja = NA,
  prix_poulet = NA,
  post2011 = 1  # toutes les années >2011
)

# Initialisation avec la dernière année réelle
future_lvl[1, c("PIB", "Population", "CPI", "Beef_price", "prix_soja", "prix_poulet")] <- 
  last_row[c("PIB", "Population", "CPI", "Beef_price", "prix_soja", "prix_poulet")]

# -----------------------------
# 2️⃣ Définition des scénarios annuels
# -----------------------------
scenarios <- list(
  central = list(PIB = 1.02, Population = 1.02, CPI = 1.03, 
                 Beef_price = 0.99, prix_soja = 1.0, prix_poulet = 0.993),
  pessimiste = list(PIB = 1.01, Population = 1.015, CPI = 1.04, 
                    Beef_price = 1.01, prix_soja = 1.01, prix_poulet = 1.005),
  optimiste = list(PIB = 1.03, Population = 1.015, CPI = 1.02, 
                   Beef_price = 0.98, prix_soja = 0.99, prix_poulet = 0.99)
)

# -----------------------------
# 3️⃣ Fonction de projection pour un scénario
# -----------------------------
proj_future <- function(future_lvl, scenario){
  for(i in 2:nrow(future_lvl)){
    future_lvl$PIB[i] <- future_lvl$PIB[i-1] * scenario$PIB
    future_lvl$Population[i] <- future_lvl$Population[i-1] * scenario$Population
    future_lvl$CPI[i] <- future_lvl$CPI[i-1] * scenario$CPI
    future_lvl$Beef_price[i] <- future_lvl$Beef_price[i-1] * scenario$Beef_price
    future_lvl$prix_soja[i] <- future_lvl$prix_soja[i-1] * scenario$prix_soja
    future_lvl$prix_poulet[i] <- future_lvl$prix_poulet[i-1] * scenario$prix_poulet
  }
  
  # Transformation log / ajustement CPI & population
  future_lvl <- future_lvl %>%
    mutate(
      PIB_log = log(PIB / (Population * CPI / 100)),
      Beef_price_log = log(Beef_price / (CPI / 100)),
      prix_soja_log = log(prix_soja / (CPI / 100)),
      prix_poulet_log = log(prix_poulet / (CPI / 100))
    )
  
  return(future_lvl)
}

# -----------------------------
# 4️⃣ Projeter les 3 scénarios
# -----------------------------
future_central <- proj_future(future_lvl, scenarios$central)
future_pessimiste <- proj_future(future_lvl, scenarios$pessimiste)
future_optimiste <- proj_future(future_lvl, scenarios$optimiste)

# -----------------------------
# 5️⃣ Prédiction CV avec le modèle
# -----------------------------
future_central$CV_hat <- predict(modele_reel_sojchick, 
                                 newdata = future_central, 
                                 interval = "prediction")

future_pessimiste$CV_hat <- predict(modele_reel_sojchick, 
                                    newdata = future_pessimiste, 
                                    interval = "prediction")

future_optimiste$CV_hat <- predict(modele_reel_sojchick, 
                                   newdata = future_optimiste, 
                                   interval = "prediction")

# -----------------------------
# 6️⃣ Retransformation pour obtenir la consommation réelle
# -----------------------------
retransform <- function(df){
  df %>%
    mutate(
      CV_real = exp(CV_hat[, "fit"]) * (CPI / 100),
      CV_lower = exp(CV_hat[, "lwr"]) * (CPI / 100),
      CV_upper = exp(CV_hat[, "upr"]) * (CPI / 100)
    )
}

future_central <- retransform(future_central)
future_pessimiste <- retransform(future_pessimiste)
future_optimiste <- retransform(future_optimiste)

# -----------------------------
# 7️⃣ Résultat final : tableau des 3 scénarios
# -----------------------------
library(tidyr)
library(ggplot2)

# Combiner pour visualisation
all_future <- bind_rows(
  future_central %>% mutate(scenario = "central"),
  future_pessimiste %>% mutate(scenario = "pessimiste"),
  future_optimiste %>% mutate(scenario = "optimiste")
)

# Graphique simple
ggplot(all_future, aes(x = year, y = CV_real, color = scenario)) +
  geom_line(size = 1.2) +
  geom_ribbon(aes(ymin = CV_lower, ymax = CV_upper, fill = scenario), alpha = 0.2) +
  labs(title = "Projection consommation de viande jusqu'en 2030",
       y = "Consommation de viande (ajustée CPI)",
       x = "Année") +
  theme_minimal()


library(ggplot2)
library(dplyr)

# -----------------------------
# Préparer les données historiques
# -----------------------------
historical <- data_reel_sojchick %>%
  mutate(
    CV_real = exp(CV) * (CPI / 100),  # remettre sur l’échelle réelle
    scenario = "historique",
    CV_lower = NA,
    CV_upper = NA
  ) %>%
  select(Year, CV_real, CV_lower, CV_upper, scenario)

# -----------------------------
# Combiner avec les projections
# -----------------------------
all_future_combined <- bind_rows(historical, all_future)

# -----------------------------
# Graphique avec historique + projections
# -----------------------------
ggplot(all_future_combined, aes(x = year, y = CV_real, color = scenario)) +
  geom_line(size = 1.2) +
  geom_ribbon(aes(ymin = CV_lower, ymax = CV_upper, fill = scenario), alpha = 0.2) +
  labs(
    title = "Consommation de viande : historique et projections jusqu'en 2030",
    y = "Consommation de viande (ajustée CPI)",
    x = "Année"
  ) +
  scale_color_manual(values = c(
    "historique" = "black",
    "central" = "blue",
    "pessimiste" = "red",
    "optimiste" = "green"
  )) +
  scale_fill_manual(values = c(
    "central" = "blue",
    "pessimiste" = "red",
    "optimiste" = "green"
  )) +
  theme_minimal()


```

## Bootstrap 2
```{r}
library(dplyr)
library(ggplot2)

set.seed(123)
n_boot <- 1000  # nombre de rééchantillonnages

# -----------------------------
# 1️⃣ Préparer les données historiques
# -----------------------------
historical <- data_reel_sojchick %>%
  mutate(
    CV_real = exp(CV) * (CPI / 100),  # remise à l'échelle réelle
    scenario = "historique",
    CV_lower_boot_real = NA,
    CV_upper_boot_real = NA
  ) %>%
  select(Year, CV_real, CV_lower_boot_real, CV_upper_boot_real, scenario)

# -----------------------------
# 2️⃣ Fonction bootstrap pour un scénario
# -----------------------------
bootstrap_scenario <- function(future_lvl, scenario, n_boot = 1000) {
  # Appliquer les hypothèses de croissance
  for(i in 2:nrow(future_lvl)){
    future_lvl$PIB[i] <- future_lvl$PIB[i-1] * scenario$PIB
    future_lvl$Population[i] <- future_lvl$Population[i-1] * scenario$Population
    future_lvl$CPI[i] <- future_lvl$CPI[i-1] * scenario$CPI
    future_lvl$Beef_price[i] <- future_lvl$Beef_price[i-1] * scenario$Beef_price
    future_lvl$prix_soja[i] <- future_lvl$prix_soja[i-1] * scenario$prix_soja
    future_lvl$prix_poulet[i] <- future_lvl$prix_poulet[i-1] * scenario$prix_poulet
  }
  
  # Transformation log / ajustement CPI & pop
  future_lvl <- future_lvl %>%
    mutate(
      PIB_log = log(PIB / (Population * CPI / 100)),
      Beef_price_log = log(Beef_price / (CPI / 100)),
      prix_soja_log = log(prix_soja / (CPI / 100)),
      prix_poulet_log = log(prix_poulet / (CPI / 100))
    )
  
  # -----------------------------
  # Bootstrap des résidus
  # -----------------------------
  resid_model <- residuals(modele_reel_sojchick)
  fitted_model <- fitted(modele_reel_sojchick)
  
  boot_pred <- matrix(NA, nrow = nrow(future_lvl), ncol = n_boot)
  
  for(b in 1:n_boot){
    boot_resid <- sample(resid_model, size = nrow(future_lvl), replace = TRUE)
    boot_pred[, b] <- predict(modele_reel_sojchick, newdata = future_lvl) + boot_resid
  }
  
  future_lvl <- future_lvl %>%
    mutate(
      CV_hat_real = exp(predict(modele_reel_sojchick, newdata = future_lvl)) * (CPI / 100),
      CV_lower_boot_real = exp(apply(boot_pred, 1, quantile, probs = 0.025)) * (CPI / 100),
      CV_upper_boot_real = exp(apply(boot_pred, 1, quantile, probs = 0.975)) * (CPI / 100)
    )
  
  return(future_lvl)
}

# -----------------------------
# 3️⃣ Définir les scénarios
# -----------------------------
scenarios <- list(
  central = list(PIB = 1.02, Population = 1.02, CPI = 1.03, 
                 Beef_price = 0.99, prix_soja = 1.0, prix_poulet = 0.993),
  pessimiste = list(PIB = 1.01, Population = 1.015, CPI = 1.04, 
                    Beef_price = 1.01, prix_soja = 1.01, prix_poulet = 1.005),
  optimiste = list(PIB = 1.03, Population = 1.015, CPI = 1.02, 
                   Beef_price = 0.98, prix_soja = 0.99, prix_poulet = 0.99)
)

# -----------------------------
# 4️⃣ Créer future_lvl initial
# -----------------------------
years <- 2023:2030
last_row <- tail(data_reel_sojchick, 1)

future_lvl_base <- data.frame(
  year = years,
  PIB = last_row$PIB,
  Population = last_row$Population,
  CPI = last_row$CPI,
  Beef_price = last_row$Beef_price,
  prix_soja = last_row$prix_soja,
  prix_poulet = last_row$prix_poulet,
  post2011 = 1  # toutes > 2011
)

# -----------------------------
# 5️⃣ Générer projections bootstrap
# -----------------------------
future_central <- bootstrap_scenario(future_lvl_base, scenarios$central, n_boot)
future_pessimiste <- bootstrap_scenario(future_lvl_base, scenarios$pessimiste, n_boot)
future_optimiste <- bootstrap_scenario(future_lvl_base, scenarios$optimiste, n_boot)

# Ajouter la colonne scenario
future_central$scenario <- "central"
future_pessimiste$scenario <- "pessimiste"
future_optimiste$scenario <- "optimiste"

# -----------------------------
# 6️⃣ Combiner historique et projections
# -----------------------------
all_future_combined <- bind_rows(historical, future_central, future_pessimiste, future_optimiste)

# -----------------------------
# 7️⃣ Graphique
# -----------------------------
ggplot(all_future_combined, aes(x = year, y = CV_hat_real, color = scenario)) +
  geom_line(size = 1.2) +
  geom_ribbon(aes(ymin = CV_lower_boot_real, ymax = CV_upper_boot_real, fill = scenario), alpha = 0.2) +
  labs(
    title = "Consommation de viande : historique et projections jusqu'en 2030 (bootstrap)",
    y = "Consommation de viande (ajustée CPI)",
    x = "Année"
  ) +
  scale_color_manual(values = c(
    "historique" = "black",
    "central" = "blue",
    "pessimiste" = "red",
    "optimiste" = "green"
  )) +
  scale_fill_manual(values = c(
    "central" = "blue",
    "pessimiste" = "red",
    "optimiste" = "green"
  )) +
  theme_minimal()


```

#Partie 4
#Réussir à trouver comment obtenir des prévisions jusqu'à 2030 pour pouvoir faire nos prévision avec ce super modèle au R² dégueu !
# Lucie - je pense que peut-être on peut regarder au moins des prévisions de l'état américain 
#sur qqs variables qui vont nous permettre de dire au modèle dans quel direction il faut aller

# Scénarios Gémini 
```{r}
# Création d'un dataframe pour 2025-2030
ans_futurs <- 2025:2030
n_ans <- length(ans_futurs)

# On prend la dernière valeur connue (2024) comme base
last_val <- tail(data_reel_sojchick, 1)

data_2030 <- data.frame(
  Year = ans_futurs,
  PIB = last_val$PIB + cumsum(rep(0.02, n_ans)), # +2% par an en log
  Beef_price = last_val$Beef_price + cumsum(rep(0.01, n_ans)),
  prix_soja = last_val$prix_soja + cumsum(rep(-0.005, n_ans)),
  prix_poulet = last_val$prix_poulet + cumsum(rep(0.01, n_ans))
)

library(sandwich)
library(lmtest)

# Calcul des prédictions ponctuelles
preds_point <- predict(modele_reel_sojchick, newdata = data_2030)

# Calcul manuel de l'intervalle de confiance avec la matrice Newey-West
X_futur <- model.matrix(~ PIB + Beef_price + prix_soja + prix_poulet, data = data_2030)
V_cov <- NeweyWest(modele_reel_sojchick, lag = 1)
se_preds <- sqrt(diag(X_futur %*% V_cov %*% t(X_futur)))

# Assemblage
data_2030$CV_pred <- preds_point
data_2030$lwr <- preds_point - 1.96 * se_preds
data_2030$upr <- preds_point + 1.96 * se_preds

ggplot(data_2030, aes(x = Year, y = exp(CV_pred))) +
  geom_line(color = "blue", size = 1) +
  geom_ribbon(aes(ymin = exp(lwr), ymax = exp(upr)), fill = "blue", alpha = 0.2) +
  labs(title = "Prévision de la Consommation de Viande (Réel) - Horizon 2030",
       subtitle = "Intervalles basés sur la correction de Newey-West",
       y = "Consommation (Niveau réel)", x = "Année") +
  theme_minimal()
```

# scenario version Emeline 
il semblerait que bootstrap ne soit pas optimal j'essaye des prédictions 

```{r}
# --- 1. Point d'ancrage 2024 ---
data_2024 <- tail(data_reel_sojchick, 1)
annees_prev <- 2025:2030

# --- 2. Définition des hypothèses de croissance (PIB) ---
taux_central <- c(0.0202, 0.0210, 0.0206, 0.0209, 0.0188, 0.0175)
taux_optimiste <- taux_central + 0.01 # +1% de croissance en plus
taux_pessimiste <- taux_central - 0.01 # -1% de croissance

# --- 3. Fonction pour générer le dataframe de prédiction ---
generer_prev <- function(taux_pib, nom_scenario) {
  pib_actuel <- data_2024$PIB
  pib_futur <- numeric(6)
  poulet_actuel <- data_2024$prix_poulet
  poulet_futur <- numeric(6)
  
  for(i in 1:6) {
    pib_futur[i] <- if(i==1) pib_actuel + log(1 + taux_pib[i]) else pib_futur[i-1] + log(1 + taux_pib[i])
    # On garde une hausse stable du poulet de 1.5%
    poulet_futur[i] <- if(i==1) poulet_actuel + log(1.015) else poulet_futur[i-1] + log(1.015)
  }
  
  df <- data.frame(
    Year = annees_prev, PIB = pib_futur, Beef_price = rep(data_2024$Beef_price, 6),
    prix_poulet = poulet_futur, prix_soja = rep(data_2024$prix_soja, 6),
    post2011 = rep(1, 6)
  )
  
  # Calcul des prédictions ET des erreurs standards pour l'intervalle de confiance
  preds <- predict(modele_reel_sojchick_dummy, newdata = df, se.fit = TRUE)
  
  df$year <- annees_prev
  df$CV_hat_real <- exp(preds$fit)
  df$CV_lower_boot_real <- exp(preds$fit - 1.96 * preds$se.fit) # Borne basse 95%
  df$CV_upper_boot_real <- exp(preds$fit + 1.96 * preds$se.fit) # Borne haute 95%
  df$scenario <- nom_scenario
  return(df)
}

# --- 4. Création des 3 mondes ---
df_central <- generer_prev(taux_central, "central")
df_opti    <- generer_prev(taux_optimiste, "optimiste")
df_pessi   <- generer_prev(taux_pessimiste, "pessimiste")

# --- 5. Historique pour le plot ---
df_hist_plot <- data_reel_sojchick[, c("Year", "CV")]
df_hist_plot <- data.frame(
  year = df_hist_plot$Year,
  CV_hat_real = exp(df_hist_plot$CV),
  scenario = "historique",
  CV_lower_boot_real = NA,
  CV_upper_boot_real = NA
)

# --- 6. Fusion finale ---
all_future_combined <- rbind(df_hist_plot, 
                             df_central[,c("year","CV_hat_real","scenario","CV_lower_boot_real","CV_upper_boot_real")],
                             df_opti[,c("year","CV_hat_real","scenario","CV_lower_boot_real","CV_upper_boot_real")],
                             df_pessi[,c("year","CV_hat_real","scenario","CV_lower_boot_real","CV_upper_boot_real")])




```

# graphique

```{r}
ggplot(all_future_combined, aes(x = year, y = CV_hat_real, color = scenario)) +
  geom_line(size = 1.1) +
  # Ajout des intervalles de confiance (Ribbon)
  geom_ribbon(aes(ymin = CV_lower_boot_real, ymax = CV_upper_boot_real, fill = scenario), 
              alpha = 0.15, color = NA) +
  scale_color_manual(values = c("historique" = "black", "central" = "blue", 
                                "pessimiste" = "red", "optimiste" = "darkgreen")) +
  scale_fill_manual(values = c("central" = "blue", "pessimiste" = "red", "optimiste" = "darkgreen")) +
  labs(
    title = "Prévisions de consommation de bœuf aux USA (2025-2030)",
    subtitle = "Modèle économétrique avec Intervalles de Confiance à 95%",
    x = "Année",
    y = "Consommation (Lbs par habitant)",
    caption = "Intervalles calculés via l'erreur standard du modèle (conforme aux tests de validation)"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

# Bibliographie 
Bentley J., (2017), U.S. per capita availability of total red meat, poultry, and fish down from 2007, Food Consumption and Demande, https://www.ers.usda.gov/data-products/charts-of-note/chart-detail?chartId=82559

Erol, E., & Saghaian, S. H. (2022). The COVID-19 Pandemic and Dynamics of Price Adjustment in the U.S. Beef Sector. Sustainability, 14(8), 4391. https://doi.org/10.3390/su14084391

Glynn T. Tonsor, Jayson L. Lusk, U.S. perspective: Meat demand outdoes meat avoidance, Meat Science, Volume 190, 2022, 108843, ISSN 0309-1740,
https://doi.org/10.1016/j.meatsci.2022.108843.

Hestermann, Yves Le Yaouanq, Nicolas Treich, An economic model of the meat paradox, European Economic Review, Volume 129, 2020, 103569, ISSN 0014-2921,
https://doi.org/10.1016/j.euroecorev.2020.103569.

Luke, J. R., Tonsor, G. T., & Schroeder, T. C. (2026). U.S. meat demand elasticity estimates: using publicly available data versus scanner data. Agricultural and Resource Economics Review, 1–20. doi:10.1017/age.2025.10020

OCDE/FAO (2020), Perspectives agricoles de l'OCDE et de la FAO 2020-2029, Éditions OCDE, Paris, https://doi.org/10.1787/ccc6f09c-fr.

OECD/FAO (2025), OECD-FAO Agricultural Outlook 2025-2034, OECD Publishing, Paris/FAO, Rome, https://doi.org/10.1787/601276cd-en.

Zheng, Hong & Wang, Yang & Zheng, Yan & Zhang, Hongmei & Liang, Shuping & Long, Mei. (2008). Equilibrium, kinetic and thermodynamic studies on the sorption of 4-hydroxyphenol on Cr-bentonite. Chemical Engineering Journal. 143. 117-123. 10.1016/j.cej.2007.12.022. 



